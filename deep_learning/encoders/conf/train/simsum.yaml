data:
test_size: 0.2
batch_size: 16
tokenizer: bert-base-uncased
weight_decay: 0.01
learning_rate: 0.0001
num_epochs: 5